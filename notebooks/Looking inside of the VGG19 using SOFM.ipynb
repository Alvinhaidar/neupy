{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "CURRENT_DIR = os.path.abspath(os.path.dirname(__name__))\n",
    "CNN_EXAMPLE_FILES = os.path.join(CURRENT_DIR, '..', 'examples', 'cnn')\n",
    "VGG19_WEIGHTS_FILE = os.path.join(CNN_EXAMPLE_FILES, 'files', 'vgg19.pickle')\n",
    "IMAGE_DIR = '/Users/itdxer/Downloads/images/'\n",
    "\n",
    "sys.path.append(CNN_EXAMPLE_FILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beaver',\n",
       " 'cougar_body',\n",
       " 'gerenuk',\n",
       " 'kangaroo',\n",
       " 'Leopards',\n",
       " 'llama',\n",
       " 'okapi',\n",
       " 'platypus',\n",
       " 'wild_cat']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(IMAGE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image_0001.jpg',\n",
       " 'image_0002.jpg',\n",
       " 'image_0003.jpg',\n",
       " 'image_0004.jpg',\n",
       " 'image_0005.jpg',\n",
       " 'image_0006.jpg',\n",
       " 'image_0007.jpg',\n",
       " 'image_0008.jpg',\n",
       " 'image_0009.jpg',\n",
       " 'image_0010.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beaver_images = os.listdir(os.path.join(IMAGE_DIR, 'beaver'))\n",
    "beaver_images[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing VGG19 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from imagenet_tools import download_file, load_image, deprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "theano.config.floatX = 'float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from neupy import layers\n",
    "\n",
    "\n",
    "vgg19 = layers.join(\n",
    "    layers.Input((3, 224, 224)),\n",
    "\n",
    "    layers.Convolution((64, 3, 3), padding=1, name='conv1_1') > layers.Relu(),\n",
    "    layers.Convolution((64, 3, 3), padding=1, name='conv1_2') > layers.Relu(),\n",
    "    layers.MaxPooling((2, 2)),\n",
    "\n",
    "    layers.Convolution((128, 3, 3), padding=1, name='conv2_1') > layers.Relu(),\n",
    "    layers.Convolution((128, 3, 3), padding=1, name='conv2_2') > layers.Relu(),\n",
    "    layers.MaxPooling((2, 2)),\n",
    "\n",
    "    layers.Convolution((256, 3, 3), padding=1, name='conv3_1') > layers.Relu(),\n",
    "    layers.Convolution((256, 3, 3), padding=1, name='conv3_2') > layers.Relu(),\n",
    "    layers.Convolution((256, 3, 3), padding=1, name='conv3_3') > layers.Relu(),\n",
    "    layers.Convolution((256, 3, 3), padding=1, name='conv3_4') > layers.Relu(),\n",
    "    layers.MaxPooling((2, 2)),\n",
    "\n",
    "    layers.Convolution((512, 3, 3), padding=1, name='conv4_1') > layers.Relu(),\n",
    "    layers.Convolution((512, 3, 3), padding=1, name='conv4_2') > layers.Relu(),\n",
    "    layers.Convolution((512, 3, 3), padding=1, name='conv4_3') > layers.Relu(),\n",
    "    layers.Convolution((512, 3, 3), padding=1, name='conv4_4') > layers.Relu(),\n",
    "    layers.MaxPooling((2, 2)),\n",
    "\n",
    "    layers.Convolution((512, 3, 3), padding=1, name='conv5_1') > layers.Relu(),\n",
    "    layers.Convolution((512, 3, 3), padding=1, name='conv5_2') > layers.Relu(),\n",
    "    layers.Convolution((512, 3, 3), padding=1, name='conv5_3') > layers.Relu(),\n",
    "    layers.Convolution((512, 3, 3), padding=1, name='conv5_4') > layers.Relu(),\n",
    "    layers.MaxPooling((2, 2)),\n",
    "\n",
    "    layers.Reshape(name='reshape'),\n",
    "\n",
    "    layers.Linear(4096, name='dense_1') > layers.Relu(),\n",
    "    layers.Linear(4096, name='dense_2') > layers.Relu(),\n",
    "    layers.Linear(1000, name='dense_3') > layers.Softmax(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pre-trained parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from neupy import storage\n",
    "\n",
    "if not os.path.exists(VGG19_WEIGHTS_FILE):\n",
    "    download_file(\n",
    "        url=(\n",
    "            \"http://srv70.putdrive.com/putstorage/DownloadFileHash/\"\n",
    "            \"F9A70DEA3A5A4A5QQWE2301487EWQS/vgg19.pickle\"\n",
    "        ),\n",
    "        filepath=VGG19_WEIGHTS_FILE,\n",
    "        description='Downloading weights'\n",
    "    )\n",
    "\n",
    "storage.load(vgg19, VGG19_WEIGHTS_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and pre-processing input images from Caltech-101 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(598, 3, 224, 224)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "images = []\n",
    "image_paths = []\n",
    "\n",
    "for path, directories, image_names in os.walk(IMAGE_DIR):\n",
    "    for image_name in image_names:\n",
    "        image_path = os.path.join(path, image_name)\n",
    "        image = load_image(\n",
    "            image_path,\n",
    "            image_size=(224, 224),\n",
    "            crop_size=(224, 224))\n",
    "        \n",
    "        images.append(image)\n",
    "        image_paths.append(image_path)\n",
    "        \n",
    "images = np.concatenate(images, axis=0)\n",
    "image_paths = np.array(image_paths)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagating images through the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(598, 1000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slice network is a way that layer with name\n",
    "# `dense_3` will be  the output layer\n",
    "# Basically we are excluding layer that applies\n",
    "# softmax function\n",
    "dense_3 = vgg19.end('dense_3')\n",
    "\n",
    "# Compile Theano function that we can use to\n",
    "# propagate image through the network\n",
    "dense_3_propagete = dense_3.compile()\n",
    "\n",
    "dense_3_output = dense_3_propagete(images)\n",
    "dense_3_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing and training SOFM on output from VGG19 network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Main information\n",
      "\n",
      "[ALGORITHM] SOFM\n",
      "\n",
      "[OPTION] verbose = True\n",
      "[OPTION] epoch_end_signal = None\n",
      "[OPTION] show_epoch = 1\n",
      "[OPTION] shuffle_data = False\n",
      "[OPTION] step = 0.1\n",
      "[OPTION] train_end_signal = None\n",
      "[OPTION] n_inputs = 1000\n",
      "[OPTION] distance = euclid\n",
      "[OPTION] features_grid = [25, 25]\n",
      "[OPTION] grid_type = hexagon\n",
      "[OPTION] learning_radius = 6\n",
      "[OPTION] n_outputs = None\n",
      "[OPTION] reduce_radius_after = 5\n",
      "[OPTION] reduce_std_after = 5\n",
      "[OPTION] reduce_step_after = 5\n",
      "[OPTION] std = 1\n",
      "[OPTION] weight = sample_from_data\n",
      "\n",
      "\n",
      "Start training\n",
      "\n",
      "[TRAINING DATA] shapes: (598, 1000)\n",
      "[TRAINING] Total epochs: 32\n",
      "\n",
      "------------------------------------------------\n",
      "| Epoch # | Train err | Valid err | Time       |\n",
      "------------------------------------------------\n",
      "| 1       | 1.338     | -         | 2.1 sec    |\n",
      "| 2       | 1.239     | -         | 1.9 sec    |\n",
      "| 3       | 1.236     | -         | 1.7 sec    |\n",
      "| 4       | 1.237     | -         | 1.7 sec    |\n",
      "| 5       | 1.206     | -         | 1.5 sec    |\n",
      "| 6       | 1.198     | -         | 1.5 sec    |\n",
      "| 7       | 1.197     | -         | 1.5 sec    |\n",
      "| 8       | 1.196     | -         | 1.5 sec    |\n",
      "| 9       | 1.195     | -         | 1.5 sec    |\n",
      "| 10      | 1.154     | -         | 1.6 sec    |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e10bf48b9671>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m )\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0msofm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/itdxer/.pyenv/versions/3.6.0/envs/neupy36/lib/python3.6/site-packages/neupy-0.5.2-py3.6.egg/neupy/algorithms/competitive/sofm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_train, summary, epochs)\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m             super(SOFM, self).train(\n\u001b[0;32m--> 527\u001b[0;31m                 input_train, summary=summary, epochs=epochs)\n\u001b[0m",
      "\u001b[0;32m/Users/itdxer/.pyenv/versions/3.6.0/envs/neupy36/lib/python3.6/site-packages/neupy-0.5.2-py3.6.egg/neupy/algorithms/associative/base.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_train, summary, epochs)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0minput_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             summary=summary)\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/itdxer/.pyenv/versions/3.6.0/envs/neupy36/lib/python3.6/site-packages/neupy-0.5.2-py3.6.egg/neupy/algorithms/base.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_train, target_train, input_test, target_test, epochs, epsilon, summary)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m                     \u001b[0mtrain_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mcan_compute_validation_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/itdxer/.pyenv/versions/3.6.0/envs/neupy36/lib/python3.6/site-packages/neupy-0.5.2-py3.6.egg/neupy/algorithms/associative/kohonen.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, input_train, target_train)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mindex_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_row\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_y\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from neupy import algorithms, environment\n",
    "\n",
    "environment.reproducible()\n",
    "\n",
    "data = dense_3_output\n",
    "sofm = algorithms.SOFM(\n",
    "    n_inputs=data.shape[1],\n",
    "    \n",
    "    # Feature map grid is 2 dimensions and has\n",
    "    # 625 output clusters (25 * 25).\n",
    "    features_grid=(25, 25),\n",
    "    \n",
    "    # Closest neuron (winning neuron) measures\n",
    "    # using cosine similarity\n",
    "    distance='euclid',\n",
    "    \n",
    "    # Sample weights from the data.\n",
    "    # Every weight vector will be just a sample\n",
    "    # from the input data. In this way we can\n",
    "    # ensure that initialized map will cover data\n",
    "    # at the very beggining.\n",
    "    weight='sample_from_data',\n",
    "    \n",
    "    grid_type='hexagon',\n",
    "\n",
    "    # Defines radius within we consider near by\n",
    "    # neurons as neighbours relatively to the\n",
    "    # winning neuron\n",
    "    learning_radius=6,\n",
    "    # Large radius is efficient only for the first\n",
    "    # iterations, that's why we reduce it by 1\n",
    "    # every 5 epochs.\n",
    "    reduce_radius_after=5,\n",
    "\n",
    "    # The further the neighbour neuron from the winning\n",
    "    # neuron the smaller learning rate for it. How much\n",
    "    # smaller the learning rate controls by the `std`\n",
    "    # parameter. The smaller `std` the smaller learning\n",
    "    # rate for neighboring neurons.\n",
    "    std=1,\n",
    "    # Neighbours within \n",
    "    reduce_std_after=5,\n",
    "    \n",
    "    # Learning rate\n",
    "    step=0.1,\n",
    "    # Learning rate is going to be reduced every 5 epochs\n",
    "    reduce_step_after=5,\n",
    "\n",
    "    # Shows training progress in terminal\n",
    "    verbose=True,\n",
    ")\n",
    "sofm.train(data, epochs=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing SOFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "def draw_grid(sofm, images, output_features):\n",
    "    data = images\n",
    "    clusters = sofm.predict(output_features).argmax(axis=1)\n",
    "    grid_height, grid_weight = sofm.features_grid\n",
    "    \n",
    "    plt.figure(figsize=(30, 30))\n",
    "\n",
    "    grid = gridspec.GridSpec(grid_height, grid_weight)\n",
    "    grid.update(wspace=0, hspace=0)\n",
    "\n",
    "    for row_id in range(grid_height):\n",
    "        print(\"Progress: {:.2%}\".format(row_id / grid_weight))\n",
    "\n",
    "        for col_id in range(grid_weight):\n",
    "            index = row_id * grid_height + col_id\n",
    "            clustered_samples = data[clusters == index]\n",
    "\n",
    "            if len(clustered_samples) > 0:\n",
    "                # We take the first sample, but it can be any\n",
    "                # sample from this cluster\n",
    "                sample = -deprocess(clustered_samples[0])\n",
    "\n",
    "            else:\n",
    "                # If we don't have samples in cluster then\n",
    "                # it means that there is a gap in space\n",
    "                sample = np.zeros((224, 224, 3))\n",
    "\n",
    "            plt.subplot(grid[index])\n",
    "            plt.imshow(sample)\n",
    "            plt.axis('off')\n",
    "\n",
    "    print(\"Progress: 100%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "draw_grid(sofm, images, dense_3_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
