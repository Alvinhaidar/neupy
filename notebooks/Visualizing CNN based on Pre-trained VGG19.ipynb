{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: Tue Dec 27 2016 20:33:42 EET\n",
      "\n",
      "CPython 3.4.3\n",
      "IPython 5.1.0\n",
      "\n",
      "numpy 1.11.2\n",
      "scipy 0.18.1\n",
      "neupy 0.4.1.dev0\n",
      "scikit-learn 0.18\n",
      "matplotlib 1.5.3\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -u -n -t -z -v -p numpy,scipy,neupy,scikit-learn,matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from neupy import layers, environment\n",
    "\n",
    "environment.speedup()\n",
    "\n",
    "vgg19 = layers.join(\n",
    "    layers.Input((3, 224, 224)),\n",
    "\n",
    "    layers.Convolution((64, 3, 3), padding=1, name='conv1_1') > layers.Relu(),\n",
    "    layers.Convolution((64, 3, 3), padding=1, name='conv1_2') > layers.Relu(),   \n",
    "    layers.MaxPooling((2, 2)),\n",
    "\n",
    "    layers.Convolution((128, 3, 3), padding=1, name='conv2_1') > layers.Relu(),\n",
    "    layers.Convolution((128, 3, 3), padding=1, name='conv2_2') > layers.Relu(),\n",
    "    layers.MaxPooling((2, 2)),\n",
    "\n",
    "    layers.Convolution((256, 3, 3), padding=1, name='conv3_1') > layers.Relu(),\n",
    "    layers.Convolution((256, 3, 3), padding=1, name='conv3_2') > layers.Relu(),\n",
    "    layers.Convolution((256, 3, 3), padding=1, name='conv3_3') > layers.Relu(),\n",
    "    layers.Convolution((256, 3, 3), padding=1, name='conv3_4') > layers.Relu(),\n",
    "    layers.MaxPooling((2, 2)),\n",
    "\n",
    "    layers.Convolution((512, 3, 3), padding=1, name='conv4_1') > layers.Relu(),\n",
    "    layers.Convolution((512, 3, 3), padding=1, name='conv4_2') > layers.Relu(),\n",
    "    layers.Convolution((512, 3, 3), padding=1, name='conv4_3') > layers.Relu(),\n",
    "    layers.Convolution((512, 3, 3), padding=1, name='conv4_4') > layers.Relu(),\n",
    "    layers.MaxPooling((2, 2)),\n",
    "\n",
    "    layers.Convolution((512, 3, 3), padding=1, name='conv5_1') > layers.Relu(),\n",
    "    layers.Convolution((512, 3, 3), padding=1, name='conv5_2') > layers.Relu(),\n",
    "    layers.Convolution((512, 3, 3), padding=1, name='conv5_3') > layers.Relu(),\n",
    "    layers.Convolution((512, 3, 3), padding=1, name='conv5_4') > layers.Relu(),\n",
    "    layers.MaxPooling((2, 2)),\n",
    "    \n",
    "    layers.Reshape(),\n",
    "    \n",
    "    layers.Relu(4096, name='dense_1') > layers.Dropout(0.5),\n",
    "    layers.Relu(4096, name='dense_2') > layers.Dropout(0.5),\n",
    "    layers.Softmax(1000, name='dense_3'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download VGG19 pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_file(url, filepath, description=''):\n",
    "    head_response = requests.head(url)\n",
    "    filesize = int(head_response.headers['content-length'])\n",
    "\n",
    "    response = requests.get(url, stream=True)\n",
    "    chunk_size = int(1e7)\n",
    "\n",
    "    n_iter = (filesize // chunk_size) + 1\n",
    "\n",
    "    print(description)\n",
    "    print('URL: {}'.format(url))\n",
    "    with open(filepath, \"wb\") as handle:\n",
    "        for data in tqdm(response.iter_content(chunk_size), total=n_iter):\n",
    "            handle.write(data)\n",
    "\n",
    "    print('Downloaded sucessfully')\n",
    "    \n",
    "\n",
    "FILES_DIR = os.path.join('files')\n",
    "VGG19_WEIGHTS_FILE = os.path.join(FILES_DIR, 'vgg19.pickle')\n",
    "\n",
    "if not os.path.exists(FILES_DIR):\n",
    "    os.mkdir(FILES_DIR)\n",
    "\n",
    "if not os.path.exists(VGG19_WEIGHTS_FILE):\n",
    "    download_file(\n",
    "        url=(\n",
    "            \"http://srv70.putdrive.com/putstorage/DownloadFileHash/\"\n",
    "            \"F9A70DEA3A5A4A5QQWE2301487EWQS/vgg19.pickle\"\n",
    "        ),\n",
    "        filepath=VGG19_WEIGHTS_FILE,\n",
    "        description='Downloading weights'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neupy import storage\n",
    "storage.load(vgg19, VGG19_WEIGHTS_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize learned features by different filters in different layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "conv1_2 layer:  40%|████      | 2/5 [00:10<00:16,  5.53s/it]"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def normalize(input_img_data):\n",
    "    x = input_img_data[0]\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "layer_names = ('conv1_2', 'conv2_2', 'conv3_4', 'conv4_4', 'conv5_4')\n",
    "fig, axes = plt.subplots(len(layer_names), 5, figsize=(12, 12))\n",
    "\n",
    "for i, output_layer_name in enumerate(layer_names):\n",
    "    desc = \"{} layer\".format(output_layer_name)\n",
    "    \n",
    "    x = T.tensor4()\n",
    "    res = vgg19.end(output_layer_name).output(x)\n",
    "    row_axes = axes[i]\n",
    "    \n",
    "    for j in tqdm(list(range(5)), desc=desc):\n",
    "        loss = T.mean(res[:, j, :, :])\n",
    "        grad = T.grad(loss, x)\n",
    "        grad /= (T.sqrt(T.mean(T.square(grad))) + 1e-7)\n",
    "        iterate = theano.function([x], [loss, grad])\n",
    "\n",
    "        # we start from a gray image with some noise\n",
    "        input_img_data = (np.random.random((1, 3, 224, 224)) * 20 + 128).astype(np.float32)\n",
    "\n",
    "        step = 100.\n",
    "        for _ in range(20):\n",
    "            loss_value, grads_value = iterate(input_img_data)\n",
    "            input_img_data = input_img_data + grads_value * step\n",
    "\n",
    "        input_img_data = normalize(input_img_data)\n",
    "        \n",
    "        row_axes[j].imshow(input_img_data[:, :, ::-1])\n",
    "        row_axes[j].axis('off')\n",
    "        \n",
    "    row_axes[2].set_title(output_layer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saliency map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.misc import imresize, imread\n",
    "\n",
    "def load_image(image_name, image_size=None, crop_size=None, use_bgr=True):\n",
    "    image = imread(image_name)\n",
    "\n",
    "    if image_size is not None:\n",
    "        image = imresize(image, image_size)\n",
    "\n",
    "    if crop_size is not None:\n",
    "        image = image[\n",
    "            slice(\n",
    "                (image_size[0] - crop_size[0]) // 2,\n",
    "                (image_size[0] + crop_size[0]) // 2,\n",
    "            ),\n",
    "            slice(\n",
    "                (image_size[1] - crop_size[1]) // 2,\n",
    "                (image_size[1] + crop_size[1]) // 2,\n",
    "            ),\n",
    "            :,\n",
    "        ]\n",
    "\n",
    "    if use_bgr:\n",
    "        # RGB -> BGR\n",
    "        image[:, :, (0, 1, 2)] = image[:, :, (2, 1, 0)]\n",
    "\n",
    "    image = image.astype('float32')\n",
    "\n",
    "    # Normalize channels (based on the pretrained VGG16 configurations)\n",
    "    image[:, :, 0] -= 123.68\n",
    "    image[:, :, 1] -= 116.779\n",
    "    image[:, :, 2] -= 103.939\n",
    "\n",
    "    # (height, width, channel) -> (channel, height, width)\n",
    "    image = image.transpose((2, 0, 1))\n",
    "    # (channel, height, width) -> (1, channel, height, width)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    return image\n",
    "\n",
    "dog = load_image('images/dog.jpg', image_size=(256, 256),\n",
    "                 crop_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(imread('images/dog.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deprocess(image):\n",
    "    image = image.copy()\n",
    "    image = image[0, :, :, :]\n",
    "    image = image.transpose((1, 2, 0))\n",
    "    \n",
    "    image[:, :, 0] += 123.68\n",
    "    image[:, :, 1] += 116.779\n",
    "    image[:, :, 2] += 103.939\n",
    "\n",
    "    image[:, :, (0, 1, 2)] = image[:, :, (2, 1, 0)]\n",
    "    \n",
    "    return image.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neupy import plots\n",
    "\n",
    "plt.imshow(-deprocess(dog))\n",
    "plots.saliency_map(vgg19, dog[0], alpha=0.6, sigma=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plots.saliency_map(vgg19, dog[0], mode='raw', vmin=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
